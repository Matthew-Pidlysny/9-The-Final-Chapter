"""
üéØ Neo-Beta Final Measurement Tool
==================================

Comprehensive measurement and analysis system for Neo-Beta sequences
based on all expansion types and mathematical frameworks.

Author: SuperNinja
Date: 2024
"""

import numpy as np
import time
import json
from decimal import Decimal, getcontext
from collections import Counter, defaultdict
import mpmath as mp

# Set high precision
getcontext().prec = 50
mp.mp.dps = 50

from neo_beta_system import PFunctionEngine, BetaSequenceGenerator, FlushNumberAnalyzer, SubPrimeEngine, QuarterSystem
from universal_sequence_detector import UniversalDetector, ExpansionType

class NeoBetaFinalMeasurementTool:
    """
    Final comprehensive measurement tool for Neo-Beta sequences.
    Integrates all mathematical frameworks and expansion types.
    """
    
    def __init__(self):
        self.p_engine = PFunctionEngine()
        self.beta_gen = BetaSequenceGenerator(self.p_engine)
        self.flush_analyzer = FlushNumberAnalyzer()
        self.sub_prime = SubPrimeEngine()
        self.quarter_sys = QuarterSystem()
        self.detector = UniversalDetector()
        
        # Beta sequence definition
        self.beta_sequence = [13, 4, 5, 2, 11, 12, 7, 9, 8, 6, 1, 3, 0, 10]
        
        # Mathematical constants
        self.constants = {
            'pi': mp.pi,
            'e': mp.e,
            'phi': (1 + mp.sqrt(5)) / 2,
            'sqrt2': mp.sqrt(2),
            'sqrt3': mp.sqrt(3),
            'ln2': mp.log(2),
            'golden_ratio_conjugate': (mp.sqrt(5) - 1) / 2
        }
        
        # Measurement history
        self.measurement_history = []
        
    def comprehensive_measurement(self, start_value, length=50, expansion_types=None):
        """
        Perform comprehensive measurement across all expansion types.
        """
        if expansion_types is None:
            expansion_types = [
                ExpansionType.RATIONAL,
                ExpansionType.IRRATIONAL,
                ExpansionType.REPEATING_RATIONAL,
                ExpansionType.SIMPLE_WILD,
                ExpansionType.TRANSCENDENT,
                ExpansionType.CUSTOM
            ]
        
        results = {
            'timestamp': time.time(),
            'start_value': start_value,
            'length': length,
            'measurements': {},
            'overall_validity': 0.0,
            'beta_alignment': 0.0,
            'mathematical_coherence': 0.0,
            'sequence_quality': 'UNKNOWN'
        }
        
        total_validity = 0
        beta_alignments = []
        
        for exp_type in expansion_types:
            try:
                measurement = self._measure_expansion_type(start_value, length, exp_type)
                results['measurements'][exp_type.name] = measurement
                total_validity += measurement['validity_score']
                beta_alignments.append(measurement['beta_alignment'])
            except Exception as e:
                results['measurements'][exp_type.name] = {
                    'error': str(e),
                    'validity_score': 0.0,
                    'beta_alignment': 0.0
                }
        
        # Calculate overall metrics
        results['overall_validity'] = total_validity / len(expansion_types)
        results['beta_alignment'] = np.mean(beta_alignments)
        results['mathematical_coherence'] = self._calculate_mathematical_coherence(results)
        results['sequence_quality'] = self._determine_sequence_quality(results)
        
        self.measurement_history.append(results)
        return results
    
    def _measure_expansion_type(self, start_value, length, exp_type):
        """Measure a specific expansion type."""
        params = self._get_default_params(exp_type)
        
        # Get sequence from detector
        result = self.detector.find_neo_beta_sequence(start_value, exp_type, length, params)
        
        # Calculate additional metrics
        sequence = result.sequence
        properties = result.properties
        
        measurement = {
            'validity_score': result.validity_score,
            'sequence': sequence[:10],  # First 10 elements
            'beta_alignment': self._calculate_beta_alignment(sequence),
            'pattern_consistency': self._calculate_pattern_consistency(sequence),
            'mathematical_properties': properties,
            'residue_analysis': self._analyze_residues(sequence),
            'flush_candidates': self._identify_flush_candidates(sequence),
            'p_function_correlation': self._calculate_p_function_correlation(sequence)
        }
        
        return measurement
    
    def _get_default_params(self, exp_type):
        """Get default parameters for each expansion type."""
        if exp_type == ExpansionType.SIMPLE_WILD:
            return {'wild_factor': 0.618034, 'chaos_level': 0.1}
        elif exp_type == ExpansionType.TRANSCENDENT:
            return {'constant': 'pi', 'transcendence_depth': 10}
        elif exp_type == ExpansionType.CUSTOM:
            return {'function_type': 'fibonacci'}
        elif exp_type == ExpansionType.CUSTOM:
            return {'learning_rate': 0.1}
        elif exp_type == ExpansionType.REPEATING_RATIONAL:
            return {'repetition_pattern': '333'}
        else:
            return {}
    
    def _calculate_beta_alignment(self, sequence):
        """Calculate alignment with Beta sequence."""
        if not sequence:
            return 0.0
        
        alignments = 0
        for i, num in enumerate(sequence):
            residue = int(num * 169) % 1000
            if residue == self.beta_sequence[i % len(self.beta_sequence)]:
                alignments += 1
        
        return alignments / len(sequence)
    
    def _calculate_pattern_consistency(self, sequence):
        """Calculate pattern consistency in sequence."""
        if len(sequence) < 3:
            return 0.0
        
        # Check for arithmetic progression
        diffs = [sequence[i+1] - sequence[i] for i in range(len(sequence)-1)]
        diff_variance = np.var(diffs) if diffs else 0
        
        # Lower variance = higher consistency
        consistency = 1 / (1 + diff_variance)
        return consistency
    
    def _analyze_residues(self, sequence):
        """Analyze residues in sequence."""
        residues = []
        for num in sequence:
            residue = int(num * 169) % 1000
            residues.append(residue)
        
        analysis = {
            'residues': residues[:10],
            'mean_residue': np.mean(residues),
            'residue_variance': np.var(residues),
            'unique_residues': len(set(residues)),
            'beta_matches': sum(1 for i, r in enumerate(residues) 
                              if r == self.beta_sequence[i % len(self.beta_sequence)])
        }
        
        return analysis
    
    def _identify_flush_candidates(self, sequence):
        """Identify flush numbers in sequence."""
        flush_candidates = []
        
        # Known flush numbers from Beta sequence
        known_flush = [13, 7, 3]
        
        for i, num in enumerate(sequence):
            residue = int(num * 169) % 1000
            if residue in known_flush:
                flush_candidates.append({
                    'position': i,
                    'value': num,
                    'residue': residue,
                    'flush_type': 'KNOWN'
                })
        
        return flush_candidates
    
    def _calculate_p_function_correlation(self, sequence):
        """Calculate correlation with P(x) = 1000x/169."""
        if len(sequence) < 2:
            return 0.0
        
        expected_values = [float(self.p_engine.evaluate(i)) for i in range(len(sequence))]
        actual_values = sequence[:len(expected_values)]
        
        correlation = np.corrcoef(expected_values, actual_values)[0, 1]
        return correlation if not np.isnan(correlation) else 0.0
    
    def _calculate_mathematical_coherence(self, results):
        """Calculate overall mathematical coherence."""
        coherence_score = 0.0
        valid_measurements = 0
        
        for exp_type, measurement in results['measurements'].items():
            if 'error' not in measurement:
                coherence_score += measurement['validity_score'] * measurement['beta_alignment']
                valid_measurements += 1
        
        return coherence_score / valid_measurements if valid_measurements > 0 else 0.0
    
    def _determine_sequence_quality(self, results):
        """Determine overall sequence quality."""
        validity = results['overall_validity']
        beta_alignment = results['beta_alignment']
        coherence = results['mathematical_coherence']
        
        if validity > 0.8 and beta_alignment > 0.7 and coherence > 0.6:
            return 'EXCELLENT'
        elif validity > 0.6 and beta_alignment > 0.5 and coherence > 0.4:
            return 'GOOD'
        elif validity > 0.4 and beta_alignment > 0.3 and coherence > 0.2:
            return 'FAIR'
        elif validity > 0.2:
            return 'POOR'
        else:
            return 'INVALID'
    
    def generate_measurement_report(self, results):
        """Generate comprehensive measurement report."""
        report = []
        report.append("=" * 80)
        report.append("üéØ NEO-BETA COMPREHENSIVE MEASUREMENT REPORT")
        report.append("=" * 80)
        report.append(f"Start Value: {results['start_value']}")
        report.append(f"Sequence Length: {results['length']}")
        report.append(f"Timestamp: {time.ctime(results['timestamp'])}")
        report.append("")
        
        # Overall Assessment
        report.append("üìä OVERALL ASSESSMENT")
        report.append("-" * 40)
        report.append(f"Overall Validity: {results['overall_validity']:.3f}")
        report.append(f"Beta Alignment: {results['beta_alignment']:.3f}")
        report.append(f"Mathematical Coherence: {results['mathematical_coherence']:.3f}")
        report.append(f"Sequence Quality: {results['sequence_quality']}")
        report.append("")
        
        # Expansion Type Results
        report.append("üîç EXPANSION TYPE ANALYSIS")
        report.append("-" * 40)
        
        for exp_type, measurement in results['measurements'].items():
            report.append(f"\n{exp_type}:")
            if 'error' in measurement:
                report.append(f"  ‚ùå Error: {measurement['error']}")
            else:
                report.append(f"  ‚úÖ Validity Score: {measurement['validity_score']:.3f}")
                report.append(f"  üéØ Beta Alignment: {measurement['beta_alignment']:.3f}")
                report.append(f"  üìà Pattern Consistency: {measurement['pattern_consistency']:.3f}")
                report.append(f"  üîó P-Function Correlation: {measurement['p_function_correlation']:.3f}")
                
                # Flush candidates
                flush_candidates = measurement['flush_candidates']
                if flush_candidates:
                    report.append(f"  üö∞ Flush Candidates: {len(flush_candidates)}")
                    for flush in flush_candidates[:3]:  # Show first 3
                        report.append(f"     Position {flush['position']}: {flush['value']} (residue: {flush['residue']})")
        
        # Mathematical Insights
        report.append("\nüßÆ MATHEMATICAL INSIGHTS")
        report.append("-" * 40)
        
        # Find best performing expansion types
        valid_types = [(k, v) for k, v in results['measurements'].items() 
                      if 'error' not in v]
        
        if valid_types:
            best_type = max(valid_types, key=lambda x: x[1]['validity_score'])
            report.append(f"Best Expansion Type: {best_type[0]} (Score: {best_type[1]['validity_score']:.3f})")
            
            # Beta pattern analysis
            beta_matches = [v['residue_analysis']['beta_matches'] for k, v in valid_types]
            avg_beta_matches = np.mean(beta_matches)
            report.append(f"Average Beta Matches: {avg_beta_matches:.1f}")
        
        # Recommendations
        report.append("\nüí° RECOMMENDATIONS")
        report.append("-" * 40)
        
        if results['sequence_quality'] == 'EXCELLENT':
            report.append("‚ú® This sequence shows excellent Neo-Beta properties!")
            report.append("   Consider this for high-priority mathematical applications.")
        elif results['sequence_quality'] == 'GOOD':
            report.append("üëç This sequence demonstrates good Neo-Beta characteristics.")
            report.append("   Suitable for most mathematical applications.")
        elif results['sequence_quality'] == 'FAIR':
            report.append("‚ö†Ô∏è  This sequence has moderate Neo-Beta properties.")
            report.append("   May require refinement for critical applications.")
        else:
            report.append("‚ùå This sequence shows limited Neo-Beta characteristics.")
            report.append("   Consider alternative sequences or parameters.")
        
        return "\n".join(report)
    
    def batch_analysis(self, start_values, length=30):
        """Perform batch analysis on multiple start values."""
        batch_results = {
            'timestamp': time.time(),
            'batch_size': len(start_values),
            'sequence_length': length,
            'results': {},
            'summary': {}
        }
        
        all_validities = []
        all_beta_alignments = []
        quality_distribution = defaultdict(int)
        
        for start_val in start_values:
            try:
                result = self.comprehensive_measurement(start_val, length)
                batch_results['results'][start_val] = result
                
                all_validities.append(result['overall_validity'])
                all_beta_alignments.append(result['beta_alignment'])
                quality_distribution[result['sequence_quality']] += 1
                
            except Exception as e:
                batch_results['results'][start_val] = {'error': str(e)}
        
        # Calculate summary statistics
        batch_results['summary'] = {
            'mean_validity': np.mean(all_validities) if all_validities else 0,
            'mean_beta_alignment': np.mean(all_beta_alignments) if all_beta_alignments else 0,
            'best_start_value': max(start_values, key=lambda x: batch_results['results'].get(x, {}).get('overall_validity', 0)),
            'quality_distribution': dict(quality_distribution)
        }
        
        return batch_results
    
    def save_results(self, results, filename):
        """Save results to file."""
        with open(filename, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        print(f"‚úÖ Results saved to {filename}")
    
    def load_results(self, filename):
        """Load results from file."""
        with open(filename, 'r') as f:
            return json.load(f)


def main():
    """Main demonstration of the final measurement tool."""
    print("üéØ Neo-Beta Final Measurement Tool - Comprehensive Analysis")
    print("=" * 80)
    
    tool = NeoBetaFinalMeasurementTool()
    
    # Single comprehensive measurement
    print("\nüìä Performing Comprehensive Measurement...")
    start_value = 7
    results = tool.comprehensive_measurement(start_value, length=20)
    
    # Generate and display report
    report = tool.generate_measurement_report(results)
    print(report)
    
    # Save results
    tool.save_results(results, 'neo_beta_measurement_results.json')
    
    # Batch analysis
    print("\nüîÑ Performing Batch Analysis...")
    start_values = [1, 3, 5, 7, 11, 13, 17, 19, 23, 29]
    batch_results = tool.batch_analysis(start_values, length=15)
    
    print(f"\nüìà Batch Analysis Summary:")
    print(f"   Mean Validity: {batch_results['summary']['mean_validity']:.3f}")
    print(f"   Mean Beta Alignment: {batch_results['summary']['mean_beta_alignment']:.3f}")
    print(f"   Best Start Value: {batch_results['summary']['best_start_value']}")
    print(f"   Quality Distribution: {batch_results['summary']['quality_distribution']}")
    
    # Save batch results
    tool.save_results(batch_results, 'neo_beta_batch_results.json')
    
    print("\nüéâ Comprehensive Analysis Complete!")
    print("=" * 80)


if __name__ == "__main__":
    main()